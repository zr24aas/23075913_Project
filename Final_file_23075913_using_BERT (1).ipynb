{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Libraries**"
      ],
      "metadata": {
        "id": "mbcDnd5AR_HW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sht90hJFRJvF"
      },
      "outputs": [],
      "source": [
        "# Importing necessary libraries for EDA\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from wordcloud import WordCloud\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import re\n",
        "from collections import defaultdict\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from transformers import  Trainer, TrainingArguments\n",
        "from datasets import Dataset\n",
        "!pip install transformers\n",
        "!pip install --upgrade jax jaxlib\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Set loading and Basic Information"
      ],
      "metadata": {
        "id": "RMtyUohkSLtx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('spamdataset.csv')\n",
        "# Basic dataset information\n",
        "df.info()\n",
        "\n",
        "# Checking for missing values\n",
        "df.isnull().sum()\n"
      ],
      "metadata": {
        "id": "I_NkyKRiTPCB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Label Distribution"
      ],
      "metadata": {
        "id": "07XpHt2nUJuk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the distribution of spam vs ham\n",
        "label_distribution = df['LABEL'].value_counts()\n",
        "\n",
        "# Plotting this label distribution\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x=label_distribution.index, y=label_distribution.values, palette='Set1')\n",
        "plt.title('Label Distribution (Spam vs Ham)')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7TLr3jOBUbgB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Set Cleaning and Resolve problem in above graph"
      ],
      "metadata": {
        "id": "G0-ZEg-yi2aE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardizing  the 'LABEL' column by converting all values to lowercase\n",
        "df['LABEL'] = df['LABEL'].str.lower()\n",
        "\n",
        "# Saving the cleaned dataset to a new CSV file\n",
        "df.to_csv('cleaned_spamdataset.csv', index=False)"
      ],
      "metadata": {
        "id": "H5EgP5GOi2C1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the distribution of spam vs ham\n",
        "label_distribution = df['LABEL'].value_counts()\n",
        "\n",
        "# Plotting this label distribution\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.barplot(x=label_distribution.index, y=label_distribution.values, palette='Set1')\n",
        "plt.title('Label Distribution (Spam vs Ham)')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "-DvA85jrjgje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Analysis"
      ],
      "metadata": {
        "id": "zLWi9yshWhUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic analysis of the text column\n",
        "df['TEXT_LENGTH'] = df['TEXT'].apply(len)\n",
        "\n",
        "# This is for Summary statistics of text length\n",
        "df['TEXT_LENGTH'].describe()\n",
        "\n",
        "# Plotting the distribution of text lengths\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.histplot(df['TEXT_LENGTH'], kde=True, color='blue', bins=20)\n",
        "plt.title('Distribution of Text Length')\n",
        "plt.xlabel('Text Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4evourELWkWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Counting the occurrences of URLs, Emails, and Phone Numbers\n",
        "url_count = df['URL'].value_counts()\n",
        "email_count = df['EMAIL'].value_counts()\n",
        "phone_count = df['PHONE'].value_counts()\n",
        "\n",
        "# Displaying the counts in a professional format\n",
        "print(\"\\nURL Count:\")\n",
        "print(url_count.to_string(), end=\"\\n\\n\")\n",
        "\n",
        "print(\"Email Count:\")\n",
        "print(email_count.to_string(), end=\"\\n\\n\")\n",
        "\n",
        "print(\"Phone Count:\")\n",
        "print(phone_count.to_string(), end=\"\\n\\n\")\n",
        "\n",
        "# Creating 3D-like bar plots with a professional style\n",
        "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "\n",
        "ax[0].bar(url_count.index, url_count.values, color=sns.color_palette(\"coolwarm\", len(url_count.index)))\n",
        "ax[0].set_title('Messages Containing URL', fontsize=14, fontweight='bold')\n",
        "ax[0].set_xlabel('URL Present', fontsize=12, fontweight='light')\n",
        "ax[0].set_ylabel('Count', fontsize=12, fontweight='light')\n",
        "ax[0].tick_params(axis='x', rotation=45)\n",
        "ax[0].set_facecolor('whitesmoke')\n",
        "\n",
        "ax[1].bar(email_count.index, email_count.values, color=sns.color_palette(\"coolwarm\", len(email_count.index)))\n",
        "ax[1].set_title('Messages Containing Email', fontsize=14, fontweight='bold')\n",
        "ax[1].set_xlabel('Email Present', fontsize=12, fontweight='light')\n",
        "ax[1].set_ylabel('Count', fontsize=12, fontweight='light')\n",
        "ax[1].tick_params(axis='x', rotation=45)\n",
        "ax[1].set_facecolor('whitesmoke')\n",
        "\n",
        "\n",
        "ax[2].bar(phone_count.index, phone_count.values, color=sns.color_palette(\"coolwarm\", len(phone_count.index)))\n",
        "ax[2].set_title('Messages Containing Phone Number', fontsize=14, fontweight='bold')\n",
        "ax[2].set_xlabel('Phone Number Present', fontsize=12, fontweight='light')\n",
        "ax[2].set_ylabel('Count', fontsize=12, fontweight='light')\n",
        "ax[2].tick_params(axis='x', rotation=45)\n",
        "ax[2].set_facecolor('whitesmoke')\n",
        "\n",
        "\n",
        "for axis in ax:\n",
        "    for bar in axis.patches:\n",
        "        bar.set_edgecolor('black')\n",
        "        bar.set_linewidth(1.5)\n",
        "    axis.set_facecolor('#f0f0f0')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RNo8980TYzNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Wordcloud for Spam (Smishing) vs Non-Spam (Ham) Messag"
      ],
      "metadata": {
        "id": "e4Y7I48WauFg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading dataset\n",
        "dataset = df\n",
        "\n",
        "# Wordcloud for spam messages (Smishing) vs non-spam (ham)\n",
        "ham_messages = dataset[dataset['LABEL'] == 'ham']['TEXT']\n",
        "spam_messages = dataset[dataset['LABEL'] == 'smishing']['TEXT']\n",
        "\n",
        "# Generating WordClouds\n",
        "ham_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(ham_messages))\n",
        "spam_wordcloud = WordCloud(width=800, height=400, background_color='white').generate(' '.join(spam_messages))\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 8))\n",
        "ax[0].imshow(ham_wordcloud, interpolation='bilinear')\n",
        "ax[0].axis('off')\n",
        "ax[0].set_title('Wordcloud for Ham Messages')\n",
        "\n",
        "ax[1].imshow(spam_wordcloud, interpolation='bilinear')\n",
        "ax[1].axis('off')\n",
        "ax[1].set_title('Wordcloud for Smishing Messages')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9lUKvfs8aURc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv('spamdataset.csv')\n",
        "\n",
        "#Heatmap showing the correlation between numerical features (URL, EMAIL, PHONE) - As binary features\n",
        "# First, we are converting URL, EMAIL, and PHONE to binary (0 for No, 1 for Yes)\n",
        "dataset['URL'] = dataset['URL'].apply(lambda x: 0 if x == 'No' else 1)\n",
        "dataset['EMAIL'] = dataset['EMAIL'].apply(lambda x: 0 if x == 'No' else 1)\n",
        "dataset['PHONE'] = dataset['PHONE'].apply(lambda x: 0 if x == 'No' else 1)\n",
        "\n",
        "# Correlation matrix for binary features\n",
        "correlation_matrix = dataset[['URL', 'EMAIL', 'PHONE']].corr()\n",
        "\n",
        "# Plotting the heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='Reds', fmt='.2f', linewidths=0.5)\n",
        "plt.title('Correlation Heatmap for URL, Email, and Phone Columns', fontsize=14, fontweight='bold')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "dSqz4j9LazDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BERT Implementation\n"
      ],
      "metadata": {
        "id": "4r8bjSHqqo_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the cleaned dataset\n",
        "df = pd.read_csv('cleaned_spamdataset.csv')\n",
        "\n",
        "# Preprocessing dataset\n",
        "df['LABEL'] = df['LABEL'].apply(lambda x: 0 if x == 'ham' else 1)  # Converting 'ham' to 0 and 'spam'/'Smishing' to 1\n",
        "\n",
        "# Splitting dataset into training and testing sets (80% train, 20% test)\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(df['TEXT'], df['LABEL'], test_size=0.2, stratify=df['LABEL'], random_state=42)\n",
        "\n",
        "# Loading BERT tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "\n",
        "# Tokenizastion the texts\n",
        "max_length = 128  # Limit sequence length\n",
        "train_encodings = tokenizer(list(train_texts), truncation=True, padding=True, max_length=max_length)\n",
        "test_encodings = tokenizer(list(test_texts), truncation=True, padding=True, max_length=max_length)\n",
        "\n",
        "# Creating TensorDatasets for training and testing\n",
        "train_dataset = TensorDataset(torch.tensor(train_encodings['input_ids']),\n",
        "                               torch.tensor(train_encodings['attention_mask']),\n",
        "                               torch.tensor(train_labels.tolist()))\n",
        "\n",
        "test_dataset = TensorDataset(torch.tensor(test_encodings['input_ids']),\n",
        "                              torch.tensor(test_encodings['attention_mask']),\n",
        "                              torch.tensor(test_labels.tolist()))\n",
        "\n",
        "# Creating DataLoader for batching\n",
        "batch_size = 16\n",
        "train_dataloader = DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
        "\n",
        "# Moving the model to GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Setting up optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
        "epochs = 5  # Setting the number of epochs for training\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Setting model to training mode\n",
        "    total_loss = 0\n",
        "    correct_predictions = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for batch in train_dataloader:\n",
        "        # Moving batch data to device (GPU or CPU)\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, attention_mask, labels = batch\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        logits = outputs.logits\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        # Calculating loss and accuracy\n",
        "        total_loss += loss.item()\n",
        "        predictions = torch.argmax(logits, dim=1)\n",
        "        correct_predictions += torch.sum(predictions == labels).item()\n",
        "        total_predictions += len(labels)\n",
        "\n",
        "    # Calculating average loss and accuracy for the epoch\n",
        "    avg_train_loss = total_loss / len(train_dataloader)\n",
        "    train_accuracy = correct_predictions / total_predictions\n",
        "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {avg_train_loss:.4f}, Accuracy: {train_accuracy:.4f}\")\n",
        "\n",
        "# Evaluation\n",
        "model.eval()  # Setting model to evaluation mode\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    input_ids, attention_mask, labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "\n",
        "    predictions.extend(torch.argmax(logits, dim=1).tolist())\n",
        "    true_labels.extend(labels.tolist())\n",
        "\n",
        "# Calculatting accuracy on the test set\n",
        "accuracy = accuracy_score(true_labels, predictions)\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Printting the classification report and confusion matrix\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(true_labels, predictions))\n",
        "\n",
        "# Plotting confusion matrix\n",
        "cm = confusion_matrix(true_labels, predictions)\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['ham', 'spam'], yticklabels=['ham', 'spam'])\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_CS8rA73s5Ni"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter Tunning"
      ],
      "metadata": {
        "id": "jFLURroV0OkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining hyperparameter search space\n",
        "learning_rates = [1e-5, 2e-5, 3e-5]\n",
        "batch_sizes = [16, 32]\n",
        "epochs = 3  # Number of epochs to train (this can also be tuned, but we'll keep it fixed for now)\n",
        "\n",
        "# Performing Random Search\n",
        "best_accuracy = 0\n",
        "best_params = {}\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for batch_size in batch_sizes:\n",
        "        print(f\"Training with Learning Rate: {lr}, Batch Size: {batch_size}\")\n",
        "\n",
        "        # Reinitializing the model and optimizer with new parameters\n",
        "        model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
        "        model.to(device)\n",
        "\n",
        "        optimizer = AdamW(model.parameters(), lr=lr)\n",
        "        total_steps = len(train_dataloader) * epochs\n",
        "        scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "        # Training the model with the current hyperparameters\n",
        "        for epoch in range(epochs):\n",
        "            model.train()  # Setting model to training mode\n",
        "            total_loss = 0\n",
        "            correct_predictions = 0\n",
        "            total_predictions = 0\n",
        "\n",
        "            for batch in DataLoader(train_dataset, sampler=RandomSampler(train_dataset), batch_size=batch_size):\n",
        "                batch = tuple(t.to(device) for t in batch)\n",
        "                input_ids, attention_mask, labels = batch\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs.loss\n",
        "                logits = outputs.logits\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                # Calculateingaccuracy\n",
        "                total_loss += loss.item()\n",
        "                predictions = torch.argmax(logits, dim=1)\n",
        "                correct_predictions += torch.sum(predictions == labels).item()\n",
        "                total_predictions += len(labels)\n",
        "\n",
        "        # Evaluating the model\n",
        "        model.eval()\n",
        "        predictions, true_labels = [], []\n",
        "        for batch in test_dataloader:\n",
        "            batch = tuple(t.to(device) for t in batch)\n",
        "            input_ids, attention_mask, labels = batch\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(input_ids, attention_mask=attention_mask)\n",
        "            logits = outputs.logits\n",
        "\n",
        "            predictions.extend(torch.argmax(logits, dim=1).tolist())\n",
        "            true_labels.extend(labels.tolist())\n",
        "\n",
        "        # Calculating validation accuracy\n",
        "        val_accuracy = accuracy_score(true_labels, predictions)\n",
        "        print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        # Tracking the best parameters based on validation accuracy\n",
        "        if val_accuracy > best_accuracy:\n",
        "            best_accuracy = val_accuracy\n",
        "            best_params = {'learning_rate': lr, 'batch_size': batch_size}\n",
        "\n",
        "print(f\"Best Hyperparameters: {best_params}\")\n"
      ],
      "metadata": {
        "id": "XVzkgaNg3HF-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}